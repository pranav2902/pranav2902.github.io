---
layout: page
title: "About Me"
permalink: /about/
---

Hey there, this is Pranav, and Welcome to my site! I am working as an ML Engineer currently at Deep Market Making Inc, and graduated from NYU Courant, with an MS in Computational Science, focussing on Machine Learning, in 2023! 

I am interested in ML Engineering, and applying NLP and Computer Vision to various problems. 

On this website, you can find a list of my projects and learnings in ML, my CV, my thoughts/opinions on various things, and maybe a few Sudokus and puzzles here and there! :)

[Github](https://github.com/pranav2902)   
[LinkedIn](https://www.linkedin.com/in/pranav-kamesh-8aa88520)

## Projects
### [Satellite Image Segmentation using U-Nets - Vision](https://github.com/pranav2902/SatelliteImagesSegmentation_Unet)

* Trained U-Net models with ResNet-18 and ResNet-50 encoders on the LandCover.ai dataset for Satellite Image Segmentation                                                        
* Augmented the given dataset with relevant transformations to balance the dataset, which improved the results.                                                                                  
* Compared the performance of Vanilla U-Net model with U-Nets with ResNet encoders, for both the original and Augmented datasets.                                                    
* Obtained a Classification accuracy of 0.88 for U-Net+ResNet-18 model, which is in line with previous benchmarks. 

**Remarks:** This was my course project for Computer Vision at NYU Courant.

### [Unlearning the bias of a Dataset using BERT Models - NLP](https://github.com/pranav2902/Unlearning-the-bias-of-a-dataset)

* Utilized concepts from He et al’s work – (Unlearn Dataset Bias in NLI by Fitting the Residual) to train a BERT model for textual entailment task.                                        
* Obtained an accuracy of 0.898 with BERT model on the Stanford NLI dataset, improving upon the benchmark set in He’s work.

**Remarks:** This was my course project for Deep Learning Systems at NYU Courant.

### Emotion Masked Language Modeling

* Reproduced the results of Sosea et al ’s work – (eMLM: A New Pre-training Objective for Emotion Related Tasks), which introduced a new pre-training 
objective, emotion Masked Language Modeling(eMLM) to BERT models to improve their performance specifically for Sentiment Analysis and Emotion 
Detection tasks.                                                                                                                
* Obtained similar results to the paper upon testing on 2 Sentiment Analysis and Emotion detection datasets. 

**Remarks:** This was my course project for NLP at NYU Courant.

### [Whatsapp Chat Analysis](https://github.com/pranav2902/Whatsapp-Text-Analysis)









